{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZgeVkW0zhWxJ",
        "hjr3Yy1i8PAr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code is part of Master's Thesis titled *Investigating the Dune Systems of Coastal Bangladesh Using Unmanned Aerial Vehicle (UAV): A Case Study at Sonadia Island.*\n",
        "\n",
        "**Author**: [Padmanabha Chowdhury](mailto:chowpadmanabha@gmail.com), MS Student (Physical Geography), Department of Geography and Environment, University of Dhaka, Bangladesh\n",
        "\n",
        "**Supervisor**: Dr. M. Shahidul Islam, Professor, Department of Geography and Environment, University of Dhaka, Bangladesh"
      ],
      "metadata": {
        "id": "_cBhpmh6sX8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u81u6Sj7gZ1b",
        "outputId": "fca8b9db-5df1-434e-ff90-86a2b933fcca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Import Packages**"
      ],
      "metadata": {
        "id": "97_ranmY6r_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Data Handling Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Package for Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Packages for Statistical Tests\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Packages for Machine Learning and Sensitivity Analysis\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "hlecXzODghZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define Functions**"
      ],
      "metadata": {
        "id": "ZgeVkW0zhWxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CALCULATE p-values of ANOVA\n",
        "\n",
        "'''\n",
        "Define Function Parameters\n",
        "\n",
        "Function ==> ANOVA (df, group_col, numeric_cols)\n",
        "\n",
        "df = dataframe which contains the dataset\n",
        "group_col = column with the values of categorical variable\n",
        "numeric_cols = columns with the independent variables\n",
        "\n",
        "'''\n",
        "\n",
        "def ANOVA(df, group_col, numeric_cols):\n",
        "    # Store results in a list\n",
        "    results = []\n",
        "\n",
        "    # Perform ANOVA using statsmodels\n",
        "    for col in numeric_cols:\n",
        "        formula = f'Q(\"{col}\") ~ C(Q(\"{group_col}\"))'\n",
        "        model = ols(formula, data=df).fit()\n",
        "        anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "        # Extract the row corresponding to the group column\n",
        "        row = anova_table.loc[f'C(Q(\"{group_col}\"))']\n",
        "\n",
        "        results.append({\n",
        "            'col': col,\n",
        "            'df': row['df'],\n",
        "            'sum_sq': row['sum_sq'],\n",
        "            'mean_sq': row['sum_sq'] / row['df'],\n",
        "            'F': row['F'],\n",
        "            'p': row['PR(>F)']\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "Rz21yqVRhHqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Processing**"
      ],
      "metadata": {
        "id": "hjr3Yy1i8PAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, clean the data to check missing, null or inconsistent values. Since all factors don't have same data range, we need to standardize them. It will enhance classification performance."
      ],
      "metadata": {
        "id": "EvRgKILuCrmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "folder = 'drive/My Drive/Dataset'\n",
        "dune=pd.read_csv(folder+'/Data.csv')\n",
        "dune"
      ],
      "metadata": {
        "id": "T5RtcpdhgpxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Null Values\n",
        "# print(dune.isnull().sum())\n",
        "\n",
        "# Delete Rows with Null Values\n",
        "df_dune_cleaned = dune.dropna(how='any')\n",
        "print(df_dune_cleaned.isnull().sum())"
      ],
      "metadata": {
        "id": "kbYrHcmV7Nkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STANDARDIZE VARIABLES\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Identify the Factors to Scale\n",
        "cols_to_scale = df_dune_cleaned.loc[:,'Length':].columns\n",
        "\n",
        "# Set the columns to Float before Scaling\n",
        "df_dune_cleaned[cols_to_scale] = df_dune_cleaned[cols_to_scale].astype(float)\n",
        "df_dune_cleaned.loc[:, cols_to_scale] = scaler.fit_transform(df_dune_cleaned.loc[:, cols_to_scale])\n",
        "# df_dune_cleaned"
      ],
      "metadata": {
        "id": "wRtlJFL3iDeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Significance Analysis**"
      ],
      "metadata": {
        "id": "JOAwqfBOCsUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conduct a one-way ANOVA test to check whether dune classes have significant variations among all morphological, oceanographic, meteorological and anthropogenic factors."
      ],
      "metadata": {
        "id": "b9Gi2ZVfDVYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate p-value of one-way ANOVA for each dune class\n",
        "# ANOVA (df, group_col, numeric_cols)\n",
        "# df = dataframe which contains the dataset\n",
        "# group_col = column with the values of categorical variable\n",
        "# numeric_cols = columns with the independent variables\n",
        "\n",
        "p_value= ANOVA(df_dune_cleaned,df_dune_cleaned.columns[3],df_dune_cleaned.columns[4:26])\n",
        "p_value\n",
        "# print(p_value[p_value['p'] < 0.01])"
      ],
      "metadata": {
        "id": "LKGDgg5C0mZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Sensitivity Analysis**"
      ],
      "metadata": {
        "id": "XTZx_JmKFDuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conduct a sensitivity analysis using the Jackknife test and XGBoost model on previously used factors of dune dynamics to identify which variables have higher relative contributions in distinguishing dune classes."
      ],
      "metadata": {
        "id": "4zJJZ5FrDjSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost and Jackknife Test for Sensitivity Analysis\n",
        "\n",
        "# Define Data for Training and Testing\n",
        "X = df_dune_cleaned.iloc[:, 4:26] # Independent Variables or Factors\n",
        "y = df_dune_cleaned['Class_General'] # Dune Classes\n",
        "\n",
        "# Encode Class Labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split Data for Training and Testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# Binarize All Class Labels\n",
        "classes = np.arange(len(le.classes_))\n",
        "y_test_binarized = label_binarize(y_test, classes=classes)\n",
        "\n",
        "# Train the Full Model\n",
        "model_full = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "model_full.fit(X_train, y_train)\n",
        "y_pred_proba_full = model_full.predict_proba(X_test)\n",
        "full_auc = roc_auc_score(y_test_binarized, y_pred_proba_full, average='macro')\n",
        "\n",
        "print(f\"Full model AUC: {full_auc:.4f}\")\n",
        "\n",
        "# Store AUCs without and with Only One Factor\n",
        "results = {\n",
        "    'feature': [],\n",
        "    'without_variable': [],\n",
        "    'with_only_variable': []\n",
        "}\n",
        "\n",
        "# Conduct the Jackknife Test\n",
        "for feature in X.columns:\n",
        "\n",
        "    # Without the feature\n",
        "    X_train_wo = X_train.drop(columns=[feature])\n",
        "    X_test_wo = X_test.drop(columns=[feature])\n",
        "    model_wo = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "    model_wo.fit(X_train_wo, y_train)\n",
        "    y_pred_proba_wo = model_wo.predict_proba(X_test_wo)\n",
        "    auc_wo = roc_auc_score(y_test_binarized, y_pred_proba_wo, average='macro')\n",
        "\n",
        "    # With only the feature\n",
        "    X_train_only = X_train[[feature]]\n",
        "    X_test_only = X_test[[feature]]\n",
        "    model_only = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "    model_only.fit(X_train_only, y_train)\n",
        "    y_pred_proba_only = model_only.predict_proba(X_test_only)\n",
        "    auc_only = roc_auc_score(y_test_binarized, y_pred_proba_only, average='macro')\n",
        "\n",
        "    results['feature'].append(feature)\n",
        "    results['without_variable'].append(auc_wo)\n",
        "    results['with_only_variable'].append(auc_only)\n",
        "\n",
        "df_results = pd.DataFrame(results).set_index('feature')\n",
        "\n",
        "# Plot Bars of the Jackknife Test Results\n",
        "features = df_results.index.tolist()\n",
        "n_features = len(features)\n",
        "\n",
        "ind = np.arange(n_features + 1)\n",
        "bar_height = 0.6\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(21, 18))\n",
        "\n",
        "ax.barh(ind[:-1], df_results['without_variable'], height=bar_height, color='steelblue', label='Without Variable')\n",
        "ax.barh(ind[:-1], df_results['with_only_variable'], height=bar_height, color='lightcoral', label='With Only Variable')\n",
        "ax.barh(ind[-1], full_auc, height=bar_height, color='#86bf73', label='With All Variables')\n",
        "\n",
        "ax.set_yticks(ind)\n",
        "ax.set_yticklabels(features + ['Full Model'])\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_xticks(np.arange(0, 1.01, 0.2))\n",
        "ax.set_yticklabels(features + ['Full Model'], fontsize=24, color='k')\n",
        "\n",
        "# X-axis label\n",
        "ax.set_xlabel('AUC', fontweight='bold', fontsize=24)\n",
        "\n",
        "# Legend Format\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1.01, 0.5), fontsize=24, borderaxespad=0.)\n",
        "\n",
        "# xtick Format\n",
        "ax.tick_params(axis='x', colors='k', labelsize=24)\n",
        "\n",
        "# Export High Resolution Image to Google Drive\n",
        "save_path = ''\n",
        "plt.savefig(save_path, dpi=800, bbox_inches='tight',facecolor='white')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oiHi7dzke-VJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}